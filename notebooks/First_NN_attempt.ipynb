{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c23375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 19:56:20.047893: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-05 19:56:20.589425: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-05 19:56:20.592282: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-05 19:56:30.413771: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import re\n",
    "#import random\n",
    "#from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, roc_auc_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import auc, accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV\n",
    "#from string import ascii_letters\n",
    "import seaborn as sns\n",
    "import h5py as h5\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc6eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, InputLayer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40d82222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64defeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac566e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../pickle_pd/pd_top_25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a36871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lep_pt_2</th>\n",
       "      <th>met_et</th>\n",
       "      <th>lep_pt_1</th>\n",
       "      <th>jet_n</th>\n",
       "      <th>lep_E_1</th>\n",
       "      <th>jet_pt_0</th>\n",
       "      <th>lep_eta_0</th>\n",
       "      <th>jet_pt_1</th>\n",
       "      <th>lep_pt_0</th>\n",
       "      <th>lep_E_2</th>\n",
       "      <th>...</th>\n",
       "      <th>jet_m</th>\n",
       "      <th>lep_E_0</th>\n",
       "      <th>jet_eta_1</th>\n",
       "      <th>jet_pt_2</th>\n",
       "      <th>lep_pt_3</th>\n",
       "      <th>jet_E_0</th>\n",
       "      <th>lep_charge_1</th>\n",
       "      <th>lep_charge_0</th>\n",
       "      <th>lep_E_3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8604.807617</td>\n",
       "      <td>34466.183594</td>\n",
       "      <td>36824.394531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37284.203125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.665586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58844.101562</td>\n",
       "      <td>8606.623047</td>\n",
       "      <td>...</td>\n",
       "      <td>4666.577148</td>\n",
       "      <td>72366.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13054.372070</td>\n",
       "      <td>32843.285156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33086.371094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50064.492188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4666.577148</td>\n",
       "      <td>55497.660156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14819.154297</td>\n",
       "      <td>14494.322266</td>\n",
       "      <td>43711.828125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54970.597656</td>\n",
       "      <td>34171.484375</td>\n",
       "      <td>1.684675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45343.480469</td>\n",
       "      <td>27666.873047</td>\n",
       "      <td>...</td>\n",
       "      <td>5185.404785</td>\n",
       "      <td>126422.304688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10125.891602</td>\n",
       "      <td>78158.171875</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10297.296875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22682.914062</td>\n",
       "      <td>16763.203125</td>\n",
       "      <td>27512.105469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77148.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28012.630859</td>\n",
       "      <td>30668.925781</td>\n",
       "      <td>...</td>\n",
       "      <td>5185.404785</td>\n",
       "      <td>28025.904297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13098.041992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>14539.251953</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>78260.984375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>199608.000000</td>\n",
       "      <td>-0.026822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74441.789062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23130.806641</td>\n",
       "      <td>74468.570312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>249863.078125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lep_pt_2        met_et      lep_pt_1  jet_n       lep_E_1  \\\n",
       "0   8604.807617  34466.183594  36824.394531    0.0  37284.203125   \n",
       "1      0.000000  13054.372070  32843.285156    0.0  33086.371094   \n",
       "2  14819.154297  14494.322266  43711.828125    1.0  54970.597656   \n",
       "3  22682.914062  16763.203125  27512.105469    0.0  77148.039062   \n",
       "4      0.000000  78260.984375      0.000000    1.0      0.000000   \n",
       "\n",
       "        jet_pt_0  lep_eta_0  jet_pt_1      lep_pt_0       lep_E_2  ...  \\\n",
       "0       0.000000  -0.665586       0.0  58844.101562   8606.623047  ...   \n",
       "1       0.000000   0.461765       0.0  50064.492188      0.000000  ...   \n",
       "2   34171.484375   1.684675       0.0  45343.480469  27666.873047  ...   \n",
       "3       0.000000  -0.030784       0.0  28012.630859  30668.925781  ...   \n",
       "4  199608.000000  -0.026822       0.0  74441.789062      0.000000  ...   \n",
       "\n",
       "          jet_m        lep_E_0  jet_eta_1  jet_pt_2      lep_pt_3  \\\n",
       "0   4666.577148   72366.562500        0.0       0.0      0.000000   \n",
       "1   4666.577148   55497.660156        0.0       0.0      0.000000   \n",
       "2   5185.404785  126422.304688        0.0       0.0  10125.891602   \n",
       "3   5185.404785   28025.904297        0.0       0.0  13098.041992   \n",
       "4  23130.806641   74468.570312        0.0       0.0      0.000000   \n",
       "\n",
       "         jet_E_0  lep_charge_1  lep_charge_0       lep_E_3  label  \n",
       "0       0.000000          -1.0           1.0      0.000000      0  \n",
       "1       0.000000          -1.0           1.0      0.000000      0  \n",
       "2   78158.171875          -1.0           1.0  10297.296875      0  \n",
       "3       0.000000           1.0          -1.0  14539.251953      0  \n",
       "4  249863.078125           0.0           1.0      0.000000      0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f3df38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop('label')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eac490ac",
   "metadata": {},
   "source": [
    "def create_model(units=64, activation='relu', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=units, activation=activation, input_dim=input_dim))\n",
    "    model.add(Dense(units=units, activation=activation))\n",
    "    model.add(Dense(units=output_dim, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b2b27e3",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'units': [32, 64, 128],\n",
    "    'activation': ['relu', 'sigmoid'],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a1531d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_one_hot = tf.keras.utils.to_categorical(y_encoded)\n",
    "\n",
    "# Shuffle and split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y_one_hot, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9099d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a65c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea3c1fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333251, 25)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "473c5662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               3328      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,779\n",
      "Trainable params: 11,779\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fe785c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "651/651 [==============================] - 3s 3ms/step - loss: 0.5501 - accuracy: 0.7645 - val_loss: 0.4678 - val_accuracy: 0.8040\n",
      "Epoch 2/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.4525 - accuracy: 0.8101 - val_loss: 0.4342 - val_accuracy: 0.8214\n",
      "Epoch 3/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.4261 - accuracy: 0.8251 - val_loss: 0.4149 - val_accuracy: 0.8292\n",
      "Epoch 4/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.4092 - accuracy: 0.8342 - val_loss: 0.4021 - val_accuracy: 0.8385\n",
      "Epoch 5/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3979 - accuracy: 0.8407 - val_loss: 0.3960 - val_accuracy: 0.8415\n",
      "Epoch 6/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3898 - accuracy: 0.8438 - val_loss: 0.3878 - val_accuracy: 0.8452\n",
      "Epoch 7/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3831 - accuracy: 0.8464 - val_loss: 0.3810 - val_accuracy: 0.8494\n",
      "Epoch 8/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3788 - accuracy: 0.8490 - val_loss: 0.3769 - val_accuracy: 0.8508\n",
      "Epoch 9/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3751 - accuracy: 0.8503 - val_loss: 0.3749 - val_accuracy: 0.8521\n",
      "Epoch 10/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3711 - accuracy: 0.8523 - val_loss: 0.3753 - val_accuracy: 0.8512\n",
      "Epoch 11/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3681 - accuracy: 0.8534 - val_loss: 0.3707 - val_accuracy: 0.8526\n",
      "Epoch 12/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3656 - accuracy: 0.8546 - val_loss: 0.3699 - val_accuracy: 0.8534\n",
      "Epoch 13/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3641 - accuracy: 0.8554 - val_loss: 0.3682 - val_accuracy: 0.8552\n",
      "Epoch 14/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3613 - accuracy: 0.8564 - val_loss: 0.3642 - val_accuracy: 0.8564\n",
      "Epoch 15/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3586 - accuracy: 0.8581 - val_loss: 0.3616 - val_accuracy: 0.8576\n",
      "Epoch 16/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3565 - accuracy: 0.8592 - val_loss: 0.3598 - val_accuracy: 0.8573\n",
      "Epoch 17/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3553 - accuracy: 0.8591 - val_loss: 0.3638 - val_accuracy: 0.8536\n",
      "Epoch 18/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3532 - accuracy: 0.8607 - val_loss: 0.3604 - val_accuracy: 0.8579\n",
      "Epoch 19/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3513 - accuracy: 0.8611 - val_loss: 0.3600 - val_accuracy: 0.8584\n",
      "Epoch 20/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3498 - accuracy: 0.8622 - val_loss: 0.3522 - val_accuracy: 0.8613\n",
      "Epoch 21/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3482 - accuracy: 0.8627 - val_loss: 0.3536 - val_accuracy: 0.8601\n",
      "Epoch 22/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3461 - accuracy: 0.8638 - val_loss: 0.3520 - val_accuracy: 0.8607\n",
      "Epoch 23/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3455 - accuracy: 0.8640 - val_loss: 0.3505 - val_accuracy: 0.8624\n",
      "Epoch 24/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3438 - accuracy: 0.8645 - val_loss: 0.3513 - val_accuracy: 0.8620\n",
      "Epoch 25/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3432 - accuracy: 0.8650 - val_loss: 0.3485 - val_accuracy: 0.8624\n",
      "Epoch 26/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3420 - accuracy: 0.8654 - val_loss: 0.3490 - val_accuracy: 0.8633\n",
      "Epoch 27/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3412 - accuracy: 0.8659 - val_loss: 0.3460 - val_accuracy: 0.8646\n",
      "Epoch 28/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3401 - accuracy: 0.8662 - val_loss: 0.3455 - val_accuracy: 0.8646\n",
      "Epoch 29/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3392 - accuracy: 0.8667 - val_loss: 0.3461 - val_accuracy: 0.8632\n",
      "Epoch 30/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3393 - accuracy: 0.8670 - val_loss: 0.3574 - val_accuracy: 0.8590\n",
      "Epoch 31/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3381 - accuracy: 0.8668 - val_loss: 0.3436 - val_accuracy: 0.8654\n",
      "Epoch 32/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3368 - accuracy: 0.8676 - val_loss: 0.3428 - val_accuracy: 0.8654\n",
      "Epoch 33/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3367 - accuracy: 0.8680 - val_loss: 0.3436 - val_accuracy: 0.8646\n",
      "Epoch 34/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3360 - accuracy: 0.8677 - val_loss: 0.3452 - val_accuracy: 0.8643\n",
      "Epoch 35/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3361 - accuracy: 0.8681 - val_loss: 0.3448 - val_accuracy: 0.8641\n",
      "Epoch 36/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3344 - accuracy: 0.8686 - val_loss: 0.3429 - val_accuracy: 0.8656\n",
      "Epoch 37/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3343 - accuracy: 0.8686 - val_loss: 0.3427 - val_accuracy: 0.8663\n",
      "Epoch 38/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3338 - accuracy: 0.8690 - val_loss: 0.3433 - val_accuracy: 0.8643\n",
      "Epoch 39/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3336 - accuracy: 0.8688 - val_loss: 0.3525 - val_accuracy: 0.8619\n",
      "Epoch 40/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3333 - accuracy: 0.8689 - val_loss: 0.3458 - val_accuracy: 0.8630\n",
      "Epoch 41/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3326 - accuracy: 0.8694 - val_loss: 0.3391 - val_accuracy: 0.8677\n",
      "Epoch 42/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3321 - accuracy: 0.8695 - val_loss: 0.3407 - val_accuracy: 0.8673\n",
      "Epoch 43/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3322 - accuracy: 0.8697 - val_loss: 0.3460 - val_accuracy: 0.8651\n",
      "Epoch 44/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3312 - accuracy: 0.8704 - val_loss: 0.3394 - val_accuracy: 0.8672\n",
      "Epoch 45/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3306 - accuracy: 0.8700 - val_loss: 0.3383 - val_accuracy: 0.8666\n",
      "Epoch 46/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3307 - accuracy: 0.8704 - val_loss: 0.3375 - val_accuracy: 0.8680\n",
      "Epoch 47/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3303 - accuracy: 0.8703 - val_loss: 0.3391 - val_accuracy: 0.8663\n",
      "Epoch 48/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3301 - accuracy: 0.8702 - val_loss: 0.3447 - val_accuracy: 0.8634\n",
      "Epoch 49/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3293 - accuracy: 0.8705 - val_loss: 0.3392 - val_accuracy: 0.8666\n",
      "Epoch 50/50\n",
      "651/651 [==============================] - 2s 3ms/step - loss: 0.3293 - accuracy: 0.8707 - val_loss: 0.3396 - val_accuracy: 0.8670\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(X_train, y_train, batch_size=512, epochs=50, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac908684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(network_history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(network_history.history['loss'])\n",
    "    plt.plot(network_history.history['val_loss'])\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(network_history.history['accuracy'])\n",
    "    plt.plot(network_history.history['val_accuracy'])\n",
    "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6e729bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86b490a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for (activation=relu - optimizer=adam - size=64\n",
      "10415/10415 [==============================] - 21s 2ms/step - loss: 0.3677 - accuracy: 0.8555\n",
      "Start training for (activation=relu - optimizer=adam - size=96\n",
      "10415/10415 [==============================] - 15s 1ms/step - loss: 0.3650 - accuracy: 0.8564\n",
      "Start training for (activation=relu - optimizer=adam - size=128\n",
      "10415/10415 [==============================] - 13s 1ms/step - loss: 0.3558 - accuracy: 0.8599\n",
      "Start training for (activation=relu - optimizer=rmsprop - size=64\n",
      "10415/10415 [==============================] - 13s 1ms/step - loss: 0.3766 - accuracy: 0.8521\n",
      "Start training for (activation=relu - optimizer=rmsprop - size=96\n",
      "10415/10415 [==============================] - 12s 1ms/step - loss: 0.3636 - accuracy: 0.8576\n",
      "Start training for (activation=relu - optimizer=rmsprop - size=128\n",
      "10415/10415 [==============================] - 13s 1ms/step - loss: 0.3615 - accuracy: 0.8590\n",
      "Start training for (activation=sigmoid - optimizer=adam - size=64\n",
      "10415/10415 [==============================] - 13s 1ms/step - loss: 0.4460 - accuracy: 0.8117\n",
      "Start training for (activation=sigmoid - optimizer=adam - size=96\n",
      "10415/10415 [==============================] - 13s 1ms/step - loss: 0.4455 - accuracy: 0.8112\n",
      "Start training for (activation=sigmoid - optimizer=adam - size=128\n",
      "10415/10415 [==============================] - 13s 1ms/step - loss: 0.4403 - accuracy: 0.8138\n",
      "Start training for (activation=sigmoid - optimizer=rmsprop - size=64\n",
      "10415/10415 [==============================] - 13s 1ms/step - loss: 0.4659 - accuracy: 0.8060\n",
      "Start training for (activation=sigmoid - optimizer=rmsprop - size=96\n",
      "10415/10415 [==============================] - 13s 1ms/step - loss: 0.4694 - accuracy: 0.8042\n",
      "Start training for (activation=sigmoid - optimizer=rmsprop - size=128\n",
      "10415/10415 [==============================] - 13s 1ms/step - loss: 0.4752 - accuracy: 0.8002\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'units': [32, 64, 128],\n",
    "    'activation': ['relu', 'sigmoid'],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "\n",
    "search_results = []\n",
    "\n",
    "size_candidates = [\n",
    "    64, 96, 128\n",
    "]\n",
    "activation_candidates = [\n",
    "  'relu', 'sigmoid'\n",
    "]\n",
    "optimizer_candidates = [\n",
    "  'adam', 'rmsprop'\n",
    "]\n",
    "dropout_candidates = [\n",
    "  .3, .4, .5\n",
    "]\n",
    "\n",
    "for nb_activation in activation_candidates:\n",
    "    for nb_optimizer in optimizer_candidates:\n",
    "        for nb_size in size_candidates:\n",
    "\n",
    "            print(f\"Start training for (activation={nb_activation} - optimizer={nb_optimizer} - size={nb_size}\")\n",
    "    \n",
    "          ########################################\n",
    "          # Use your own model here!!\n",
    "          ########################################\n",
    "            model = Sequential([\n",
    "            Dense(nb_size, activation=nb_activation, input_dim=25),\n",
    "            Dense(3, activation='softmax')\n",
    "            ])\n",
    "            \n",
    "            model.compile(loss='categorical_crossentropy', optimizer=nb_optimizer, metrics=['accuracy'])\n",
    "            \n",
    "            \n",
    "          #model = Sequential([\n",
    "          #  Conv2D(\n",
    "          #      nb_filters, kernel_size=2, padding='valid',\n",
    "          #      activation='relu', input_shape=x_train[0].shape\n",
    "          #  ),\n",
    "          #  Conv2D(\n",
    "          #      int(nb_filters*2), kernel_size=2,\n",
    "          #      padding='valid', activation='relu'\n",
    "          #  ),\n",
    "          #  MaxPooling2D(pool_size=2),\n",
    "          #  Dropout(dropout),\n",
    "          #  Flatten(),\n",
    "          #  Dense(nb_dense, activation='relu'),\n",
    "          #  Dropout(dropout),\n",
    "          #  Dense(10, activation='softmax')\n",
    "          #])\n",
    "          #model.compile(\n",
    "          #    loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']\n",
    "          #)\n",
    "          ########################################\n",
    "    \n",
    "          # we choose our best model as the one having the highest validation accuracy\n",
    "            filepath = f\"NN_train_results/cnn_paramsearch_filters_ac={nb_activation}_op={nb_optimizer}_si={nb_size}_dense=1.hdf5\"\n",
    "            checkpoint = ModelCheckpoint(\n",
    "                filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max'\n",
    "            )\n",
    "    \n",
    "          #batch_size=512, epochs=50, verbose=1, validation_data=(X_val, y_val)\n",
    "        \n",
    "            fit_results = model.fit(\n",
    "              x=X_train,\n",
    "              y=y_train,\n",
    "              batch_size=512,\n",
    "              # reduce number of epochs for speed reasons --> should be higher!\n",
    "              epochs=50,\n",
    "              validation_data=(X_val, y_val),\n",
    "              callbacks=[checkpoint],\n",
    "              verbose=0\n",
    "            )\n",
    "    \n",
    "            # extract the best validation scores\n",
    "            best_val_epoch    = np.argmax(fit_results.history['val_accuracy'])\n",
    "            best_val_acc      = np.max(fit_results.history['val_accuracy'])\n",
    "            best_val_acc_loss = fit_results.history['val_loss'][best_val_epoch]\n",
    "      \n",
    "            # get correct training accuracy\n",
    "            best_model = load_model(filepath)\n",
    "            best_val_acc_train_loss, best_val_acc_train_acc = best_model.evaluate(X_train, y_train)\n",
    "      \n",
    "            # store results\n",
    "            search_results.append({\n",
    "                'nb_activation': nb_activation,\n",
    "                'nb_optimizer': nb_optimizer,\n",
    "                #'dropout': dropout,\n",
    "                'best_val_acc_train_acc': best_val_acc_train_acc,\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'best_val_acc_train_loss': best_val_acc_train_loss,\n",
    "                'best_val_acc_loss': best_val_acc_loss,\n",
    "                'best_val_epoch': best_val_epoch\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0078af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_activation</th>\n",
       "      <th>nb_optimizer</th>\n",
       "      <th>best_val_acc_train_acc</th>\n",
       "      <th>best_val_acc</th>\n",
       "      <th>best_val_acc_train_loss</th>\n",
       "      <th>best_val_acc_loss</th>\n",
       "      <th>best_val_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.859910</td>\n",
       "      <td>0.857753</td>\n",
       "      <td>0.355811</td>\n",
       "      <td>0.360745</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.859031</td>\n",
       "      <td>0.856409</td>\n",
       "      <td>0.361465</td>\n",
       "      <td>0.366885</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.857630</td>\n",
       "      <td>0.856121</td>\n",
       "      <td>0.363621</td>\n",
       "      <td>0.368408</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.856406</td>\n",
       "      <td>0.854945</td>\n",
       "      <td>0.365049</td>\n",
       "      <td>0.369502</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.855544</td>\n",
       "      <td>0.852988</td>\n",
       "      <td>0.367678</td>\n",
       "      <td>0.372385</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.852138</td>\n",
       "      <td>0.849867</td>\n",
       "      <td>0.376570</td>\n",
       "      <td>0.380225</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.813795</td>\n",
       "      <td>0.812358</td>\n",
       "      <td>0.440311</td>\n",
       "      <td>0.442296</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.811731</td>\n",
       "      <td>0.809742</td>\n",
       "      <td>0.445961</td>\n",
       "      <td>0.447394</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.811169</td>\n",
       "      <td>0.809321</td>\n",
       "      <td>0.445524</td>\n",
       "      <td>0.447218</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.806038</td>\n",
       "      <td>0.804988</td>\n",
       "      <td>0.465949</td>\n",
       "      <td>0.467282</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.804169</td>\n",
       "      <td>0.802984</td>\n",
       "      <td>0.469391</td>\n",
       "      <td>0.470088</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.800205</td>\n",
       "      <td>0.798843</td>\n",
       "      <td>0.475164</td>\n",
       "      <td>0.476547</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_activation nb_optimizer  best_val_acc_train_acc  best_val_acc  \\\n",
       "2           relu         adam                0.859910      0.857753   \n",
       "5           relu      rmsprop                0.859031      0.856409   \n",
       "4           relu      rmsprop                0.857630      0.856121   \n",
       "1           relu         adam                0.856406      0.854945   \n",
       "0           relu         adam                0.855544      0.852988   \n",
       "3           relu      rmsprop                0.852138      0.849867   \n",
       "8        sigmoid         adam                0.813795      0.812358   \n",
       "6        sigmoid         adam                0.811731      0.809742   \n",
       "7        sigmoid         adam                0.811169      0.809321   \n",
       "9        sigmoid      rmsprop                0.806038      0.804988   \n",
       "10       sigmoid      rmsprop                0.804169      0.802984   \n",
       "11       sigmoid      rmsprop                0.800205      0.798843   \n",
       "\n",
       "    best_val_acc_train_loss  best_val_acc_loss  best_val_epoch  \n",
       "2                  0.355811           0.360745              48  \n",
       "5                  0.361465           0.366885              47  \n",
       "4                  0.363621           0.368408              49  \n",
       "1                  0.365049           0.369502              48  \n",
       "0                  0.367678           0.372385              46  \n",
       "3                  0.376570           0.380225              47  \n",
       "8                  0.440311           0.442296              49  \n",
       "6                  0.445961           0.447394              49  \n",
       "7                  0.445524           0.447218              49  \n",
       "9                  0.465949           0.467282              48  \n",
       "10                 0.469391           0.470088              49  \n",
       "11                 0.475164           0.476547              48  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(search_results)\n",
    "\n",
    "# sort values\n",
    "resultsDF.sort_values('best_val_acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d52eab1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for (activation=relu - optimizer=adam - size=64\n",
      "10415/10415 [==============================] - 13s 1ms/step - loss: 0.3426 - accuracy: 0.8657\n",
      "Start training for (activation=relu - optimizer=adam - size=96\n",
      "10415/10415 [==============================] - 13s 1ms/step - loss: 0.3300 - accuracy: 0.8707\n",
      "Start training for (activation=relu - optimizer=adam - size=128\n",
      "10415/10415 [==============================] - 17s 2ms/step - loss: 0.3282 - accuracy: 0.8712\n",
      "Start training for (activation=sigmoid - optimizer=adam - size=64\n",
      "10415/10415 [==============================] - 15s 1ms/step - loss: 0.4454 - accuracy: 0.8108\n",
      "Start training for (activation=sigmoid - optimizer=adam - size=96\n",
      "10415/10415 [==============================] - 15s 1ms/step - loss: 0.4439 - accuracy: 0.8125\n",
      "Start training for (activation=sigmoid - optimizer=adam - size=128\n",
      "10415/10415 [==============================] - 15s 1ms/step - loss: 0.4433 - accuracy: 0.8117\n",
      "Start training for (activation=sigmoid - optimizer=rmsprop - size=64\n",
      "10415/10415 [==============================] - 15s 1ms/step - loss: 0.4532 - accuracy: 0.8093\n",
      "Start training for (activation=sigmoid - optimizer=rmsprop - size=96\n",
      "10415/10415 [==============================] - 15s 1ms/step - loss: 0.4497 - accuracy: 0.8109\n",
      "Start training for (activation=sigmoid - optimizer=rmsprop - size=128\n",
      "10415/10415 [==============================] - 16s 2ms/step - loss: 0.4487 - accuracy: 0.8100\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'units': [32, 64, 128],\n",
    "    'activation': ['relu', 'sigmoid'],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "\n",
    "search_results = []\n",
    "\n",
    "size_candidates = [\n",
    "    64, 96, 128\n",
    "]\n",
    "activation_candidates = [\n",
    "  'relu', 'sigmoid'\n",
    "]\n",
    "optimizer_candidates = [\n",
    "  'adam', 'rmsprop'\n",
    "]\n",
    "dropout_candidates = [\n",
    "  .3, .4, .5\n",
    "]\n",
    "\n",
    "for nb_activation in activation_candidates:\n",
    "    for nb_optimizer in optimizer_candidates:\n",
    "        for nb_size in size_candidates:\n",
    "\n",
    "            print(f\"Start training for (activation={nb_activation} - optimizer={nb_optimizer} - size={nb_size}\")\n",
    "    \n",
    "          ########################################\n",
    "          # Use your own model here!!\n",
    "          ########################################\n",
    "            model = Sequential([\n",
    "            Dense(nb_size, activation=nb_activation, input_dim=25),\n",
    "            Dense(nb_size/2, activation=nb_activation),\n",
    "            Dense(3, activation='softmax')\n",
    "            ])\n",
    "            \n",
    "            model.compile(loss='categorical_crossentropy', optimizer=nb_optimizer, metrics=['accuracy'])\n",
    "            \n",
    "            \n",
    "          #model = Sequential([\n",
    "          #  Conv2D(\n",
    "          #      nb_filters, kernel_size=2, padding='valid',\n",
    "          #      activation='relu', input_shape=x_train[0].shape\n",
    "          #  ),\n",
    "          #  Conv2D(\n",
    "          #      int(nb_filters*2), kernel_size=2,\n",
    "          #      padding='valid', activation='relu'\n",
    "          #  ),\n",
    "          #  MaxPooling2D(pool_size=2),\n",
    "          #  Dropout(dropout),\n",
    "          #  Flatten(),\n",
    "          #  Dense(nb_dense, activation='relu'),\n",
    "          #  Dropout(dropout),\n",
    "          #  Dense(10, activation='softmax')\n",
    "          #])\n",
    "          #model.compile(\n",
    "          #    loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']\n",
    "          #)\n",
    "          ########################################\n",
    "    \n",
    "          # we choose our best model as the one having the highest validation accuracy\n",
    "            filepath = f\"NN_train_results/cnn_paramsearch_filters_ac={nb_activation}_op={nb_optimizer}_si={nb_size}_dense=2.hdf5\"\n",
    "            checkpoint = ModelCheckpoint(\n",
    "                filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max'\n",
    "            )\n",
    "    \n",
    "          #batch_size=512, epochs=50, verbose=1, validation_data=(X_val, y_val)\n",
    "        \n",
    "            fit_results = model.fit(\n",
    "              x=X_train,\n",
    "              y=y_train,\n",
    "              batch_size=512,\n",
    "              # reduce number of epochs for speed reasons --> should be higher!\n",
    "              epochs=50,\n",
    "              validation_data=(X_val, y_val),\n",
    "              callbacks=[checkpoint],\n",
    "              verbose=0\n",
    "            )\n",
    "    \n",
    "            # extract the best validation scores\n",
    "            best_val_epoch    = np.argmax(fit_results.history['val_accuracy'])\n",
    "            best_val_acc      = np.max(fit_results.history['val_accuracy'])\n",
    "            best_val_acc_loss = fit_results.history['val_loss'][best_val_epoch]\n",
    "      \n",
    "            # get correct training accuracy\n",
    "            best_model = load_model(filepath)\n",
    "            best_val_acc_train_loss, best_val_acc_train_acc = best_model.evaluate(X_train, y_train)\n",
    "      \n",
    "            # store results\n",
    "            search_results.append({\n",
    "                'nb_activation': nb_activation,\n",
    "                'nb_optimizer': nb_optimizer,\n",
    "                #'dropout': dropout,\n",
    "                'best_val_acc_train_acc': best_val_acc_train_acc,\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'best_val_acc_train_loss': best_val_acc_train_loss,\n",
    "                'best_val_acc_loss': best_val_acc_loss,\n",
    "                'best_val_epoch': best_val_epoch\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6da29c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_activation</th>\n",
       "      <th>nb_optimizer</th>\n",
       "      <th>best_val_acc_train_acc</th>\n",
       "      <th>best_val_acc</th>\n",
       "      <th>best_val_acc_train_loss</th>\n",
       "      <th>best_val_acc_loss</th>\n",
       "      <th>best_val_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.871223</td>\n",
       "      <td>0.867776</td>\n",
       "      <td>0.328223</td>\n",
       "      <td>0.339285</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.870680</td>\n",
       "      <td>0.867704</td>\n",
       "      <td>0.330008</td>\n",
       "      <td>0.337796</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.870389</td>\n",
       "      <td>0.867680</td>\n",
       "      <td>0.330281</td>\n",
       "      <td>0.338986</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.871490</td>\n",
       "      <td>0.867404</td>\n",
       "      <td>0.327329</td>\n",
       "      <td>0.337014</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.865663</td>\n",
       "      <td>0.863947</td>\n",
       "      <td>0.342563</td>\n",
       "      <td>0.349678</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.865816</td>\n",
       "      <td>0.863503</td>\n",
       "      <td>0.340826</td>\n",
       "      <td>0.348793</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.812523</td>\n",
       "      <td>0.809778</td>\n",
       "      <td>0.443916</td>\n",
       "      <td>0.445641</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.811704</td>\n",
       "      <td>0.809297</td>\n",
       "      <td>0.443273</td>\n",
       "      <td>0.445150</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.810881</td>\n",
       "      <td>0.809033</td>\n",
       "      <td>0.449673</td>\n",
       "      <td>0.451270</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.810809</td>\n",
       "      <td>0.808673</td>\n",
       "      <td>0.445411</td>\n",
       "      <td>0.446909</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.810014</td>\n",
       "      <td>0.808337</td>\n",
       "      <td>0.448686</td>\n",
       "      <td>0.450515</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.809303</td>\n",
       "      <td>0.807233</td>\n",
       "      <td>0.453202</td>\n",
       "      <td>0.455230</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_activation nb_optimizer  best_val_acc_train_acc  best_val_acc  \\\n",
       "5           relu      rmsprop                0.871223      0.867776   \n",
       "1           relu         adam                0.870680      0.867704   \n",
       "4           relu      rmsprop                0.870389      0.867680   \n",
       "2           relu         adam                0.871490      0.867404   \n",
       "0           relu         adam                0.865663      0.863947   \n",
       "3           relu      rmsprop                0.865816      0.863503   \n",
       "7        sigmoid         adam                0.812523      0.809778   \n",
       "8        sigmoid         adam                0.811704      0.809297   \n",
       "10       sigmoid      rmsprop                0.810881      0.809033   \n",
       "6        sigmoid         adam                0.810809      0.808673   \n",
       "11       sigmoid      rmsprop                0.810014      0.808337   \n",
       "9        sigmoid      rmsprop                0.809303      0.807233   \n",
       "\n",
       "    best_val_acc_train_loss  best_val_acc_loss  best_val_epoch  \n",
       "5                  0.328223           0.339285              48  \n",
       "1                  0.330008           0.337796              49  \n",
       "4                  0.330281           0.338986              49  \n",
       "2                  0.327329           0.337014              41  \n",
       "0                  0.342563           0.349678              48  \n",
       "3                  0.340826           0.348793              48  \n",
       "7                  0.443916           0.445641              49  \n",
       "8                  0.443273           0.445150              49  \n",
       "10                 0.449673           0.451270              47  \n",
       "6                  0.445411           0.446909              48  \n",
       "11                 0.448686           0.450515              45  \n",
       "9                  0.453202           0.455230              49  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(search_results)\n",
    "\n",
    "# sort values\n",
    "resultsDF.sort_values('best_val_acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bee1b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for (activation=relu - optimizer=adam - size=64\n",
      "10415/10415 [==============================] - 16s 1ms/step - loss: 0.3360 - accuracy: 0.8673\n",
      "Start training for (activation=relu - optimizer=adam - size=96\n",
      "10415/10415 [==============================] - 15s 1ms/step - loss: 0.3256 - accuracy: 0.8715\n",
      "Start training for (activation=relu - optimizer=adam - size=128\n",
      "10415/10415 [==============================] - 15s 1ms/step - loss: 0.3201 - accuracy: 0.8734\n",
      "Start training for (activation=relu - optimizer=rmsprop - size=64\n",
      "10415/10415 [==============================] - 15s 1ms/step - loss: 0.3359 - accuracy: 0.8678\n",
      "Start training for (activation=relu - optimizer=rmsprop - size=96\n",
      "10415/10415 [==============================] - 16s 1ms/step - loss: 0.3255 - accuracy: 0.8718\n",
      "Start training for (activation=relu - optimizer=rmsprop - size=128\n",
      "10415/10415 [==============================] - 16s 1ms/step - loss: 0.3180 - accuracy: 0.8745\n",
      "Start training for (activation=sigmoid - optimizer=adam - size=64\n",
      "10415/10415 [==============================] - 15s 1ms/step - loss: 0.4432 - accuracy: 0.8122\n",
      "Start training for (activation=sigmoid - optimizer=adam - size=96\n",
      "10415/10415 [==============================] - 16s 2ms/step - loss: 0.4397 - accuracy: 0.8140\n",
      "Start training for (activation=sigmoid - optimizer=adam - size=128\n",
      "10415/10415 [==============================] - 16s 2ms/step - loss: 0.4438 - accuracy: 0.8119\n",
      "Start training for (activation=sigmoid - optimizer=rmsprop - size=64\n",
      "10415/10415 [==============================] - 16s 2ms/step - loss: 0.4423 - accuracy: 0.8109\n",
      "Start training for (activation=sigmoid - optimizer=rmsprop - size=96\n",
      "10415/10415 [==============================] - 16s 2ms/step - loss: 0.4594 - accuracy: 0.8070\n",
      "Start training for (activation=sigmoid - optimizer=rmsprop - size=128\n",
      "10415/10415 [==============================] - 16s 2ms/step - loss: 0.4470 - accuracy: 0.8141\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'units': [32, 64, 128],\n",
    "    'activation': ['relu', 'sigmoid'],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "\n",
    "search_results = []\n",
    "\n",
    "size_candidates = [\n",
    "    64, 96, 128\n",
    "]\n",
    "activation_candidates = [\n",
    "  'relu', 'sigmoid'\n",
    "]\n",
    "optimizer_candidates = [\n",
    "  'adam', 'rmsprop'\n",
    "]\n",
    "dropout_candidates = [\n",
    "  .3, .4, .5\n",
    "]\n",
    "\n",
    "for nb_activation in activation_candidates:\n",
    "    for nb_optimizer in optimizer_candidates:\n",
    "        for nb_size in size_candidates:\n",
    "\n",
    "            print(f\"Start training for (activation={nb_activation} - optimizer={nb_optimizer} - size={nb_size}\")\n",
    "    \n",
    "          ########################################\n",
    "          # Use your own model here!!\n",
    "          ########################################\n",
    "            model = Sequential([\n",
    "            Dense(nb_size, activation=nb_activation, input_dim=25),\n",
    "            Dense(nb_size/2, activation=nb_activation),\n",
    "            Dense(nb_size/4, activation=nb_activation),\n",
    "            Dense(3, activation='softmax')\n",
    "            ])\n",
    "            \n",
    "            model.compile(loss='categorical_crossentropy', optimizer=nb_optimizer, metrics=['accuracy'])\n",
    "            \n",
    "            \n",
    "          #model = Sequential([\n",
    "          #  Conv2D(\n",
    "          #      nb_filters, kernel_size=2, padding='valid',\n",
    "          #      activation='relu', input_shape=x_train[0].shape\n",
    "          #  ),\n",
    "          #  Conv2D(\n",
    "          #      int(nb_filters*2), kernel_size=2,\n",
    "          #      padding='valid', activation='relu'\n",
    "          #  ),\n",
    "          #  MaxPooling2D(pool_size=2),\n",
    "          #  Dropout(dropout),\n",
    "          #  Flatten(),\n",
    "          #  Dense(nb_dense, activation='relu'),\n",
    "          #  Dropout(dropout),\n",
    "          #  Dense(10, activation='softmax')\n",
    "          #])\n",
    "          #model.compile(\n",
    "          #    loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']\n",
    "          #)\n",
    "          ########################################\n",
    "    \n",
    "          # we choose our best model as the one having the highest validation accuracy\n",
    "            filepath = f\"NN_train_results/cnn_paramsearch_filters_ac={nb_activation}_op={nb_optimizer}_si={nb_size}_dense=3.hdf5\"\n",
    "            checkpoint = ModelCheckpoint(\n",
    "                filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max'\n",
    "            )\n",
    "    \n",
    "          #batch_size=512, epochs=50, verbose=1, validation_data=(X_val, y_val)\n",
    "        \n",
    "            fit_results = model.fit(\n",
    "              x=X_train,\n",
    "              y=y_train,\n",
    "              batch_size=512,\n",
    "              # reduce number of epochs for speed reasons --> should be higher!\n",
    "              epochs=50,\n",
    "              validation_data=(X_val, y_val),\n",
    "              callbacks=[checkpoint],\n",
    "              verbose=0\n",
    "            )\n",
    "    \n",
    "            # extract the best validation scores\n",
    "            best_val_epoch    = np.argmax(fit_results.history['val_accuracy'])\n",
    "            best_val_acc      = np.max(fit_results.history['val_accuracy'])\n",
    "            best_val_acc_loss = fit_results.history['val_loss'][best_val_epoch]\n",
    "      \n",
    "            # get correct training accuracy\n",
    "            best_model = load_model(filepath)\n",
    "            best_val_acc_train_loss, best_val_acc_train_acc = best_model.evaluate(X_train, y_train)\n",
    "      \n",
    "            # store results\n",
    "            search_results.append({\n",
    "                'nb_activation': nb_activation,\n",
    "                'nb_optimizer': nb_optimizer,\n",
    "                'nb_size': nb_size,\n",
    "                #'dropout': dropout,\n",
    "                'best_val_acc_train_acc': best_val_acc_train_acc,\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'best_val_acc_train_loss': best_val_acc_train_loss,\n",
    "                'best_val_acc_loss': best_val_acc_loss,\n",
    "                'best_val_epoch': best_val_epoch\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "915eb733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_activation</th>\n",
       "      <th>nb_optimizer</th>\n",
       "      <th>nb_size</th>\n",
       "      <th>best_val_acc_train_acc</th>\n",
       "      <th>best_val_acc</th>\n",
       "      <th>best_val_acc_train_loss</th>\n",
       "      <th>best_val_acc_loss</th>\n",
       "      <th>best_val_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>128</td>\n",
       "      <td>0.874500</td>\n",
       "      <td>0.870200</td>\n",
       "      <td>0.318015</td>\n",
       "      <td>0.331268</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>128</td>\n",
       "      <td>0.873447</td>\n",
       "      <td>0.869804</td>\n",
       "      <td>0.320138</td>\n",
       "      <td>0.330706</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>96</td>\n",
       "      <td>0.871802</td>\n",
       "      <td>0.868364</td>\n",
       "      <td>0.325536</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>96</td>\n",
       "      <td>0.871454</td>\n",
       "      <td>0.867968</td>\n",
       "      <td>0.325618</td>\n",
       "      <td>0.334646</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>64</td>\n",
       "      <td>0.867256</td>\n",
       "      <td>0.865375</td>\n",
       "      <td>0.336047</td>\n",
       "      <td>0.342173</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>64</td>\n",
       "      <td>0.867760</td>\n",
       "      <td>0.864379</td>\n",
       "      <td>0.335930</td>\n",
       "      <td>0.343593</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>128</td>\n",
       "      <td>0.814098</td>\n",
       "      <td>0.812382</td>\n",
       "      <td>0.446995</td>\n",
       "      <td>0.449095</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>96</td>\n",
       "      <td>0.813966</td>\n",
       "      <td>0.811146</td>\n",
       "      <td>0.439740</td>\n",
       "      <td>0.441308</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>128</td>\n",
       "      <td>0.811893</td>\n",
       "      <td>0.809550</td>\n",
       "      <td>0.443830</td>\n",
       "      <td>0.445306</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>adam</td>\n",
       "      <td>64</td>\n",
       "      <td>0.812187</td>\n",
       "      <td>0.809453</td>\n",
       "      <td>0.443201</td>\n",
       "      <td>0.444917</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>64</td>\n",
       "      <td>0.810938</td>\n",
       "      <td>0.808661</td>\n",
       "      <td>0.442335</td>\n",
       "      <td>0.444080</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>96</td>\n",
       "      <td>0.807028</td>\n",
       "      <td>0.804724</td>\n",
       "      <td>0.459399</td>\n",
       "      <td>0.460717</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_activation nb_optimizer  nb_size  best_val_acc_train_acc  best_val_acc  \\\n",
       "5           relu      rmsprop      128                0.874500      0.870200   \n",
       "2           relu         adam      128                0.873447      0.869804   \n",
       "4           relu      rmsprop       96                0.871802      0.868364   \n",
       "1           relu         adam       96                0.871454      0.867968   \n",
       "0           relu         adam       64                0.867256      0.865375   \n",
       "3           relu      rmsprop       64                0.867760      0.864379   \n",
       "11       sigmoid      rmsprop      128                0.814098      0.812382   \n",
       "7        sigmoid         adam       96                0.813966      0.811146   \n",
       "8        sigmoid         adam      128                0.811893      0.809550   \n",
       "6        sigmoid         adam       64                0.812187      0.809453   \n",
       "9        sigmoid      rmsprop       64                0.810938      0.808661   \n",
       "10       sigmoid      rmsprop       96                0.807028      0.804724   \n",
       "\n",
       "    best_val_acc_train_loss  best_val_acc_loss  best_val_epoch  \n",
       "5                  0.318015           0.331268              45  \n",
       "2                  0.320138           0.330706              42  \n",
       "4                  0.325536           0.335590              46  \n",
       "1                  0.325618           0.334646              48  \n",
       "0                  0.336047           0.342173              46  \n",
       "3                  0.335930           0.343593              48  \n",
       "11                 0.446995           0.449095              48  \n",
       "7                  0.439740           0.441308              48  \n",
       "8                  0.443830           0.445306              46  \n",
       "6                  0.443201           0.444917              46  \n",
       "9                  0.442335           0.444080              49  \n",
       "10                 0.459399           0.460717              48  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(search_results)\n",
    "\n",
    "# sort values\n",
    "resultsDF.sort_values('best_val_acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9bc6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57ac2a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for (learn=0.001 - momentum=0.0 - candidates=0.1\n",
      "10415/10415 [==============================] - 14s 1ms/step - loss: 0.3217 - accuracy: 0.8739\n",
      "Start training for (learn=0.001 - momentum=0.0 - candidates=0.3\n",
      "10415/10415 [==============================] - 14s 1ms/step - loss: 0.3370 - accuracy: 0.8689\n",
      "Start training for (learn=0.001 - momentum=0.0 - candidates=0.5\n",
      "10415/10415 [==============================] - 13s 1ms/step - loss: 0.3614 - accuracy: 0.8630\n",
      "Start training for (learn=0.001 - momentum=0.5 - candidates=0.1\n",
      "10415/10415 [==============================] - 17s 2ms/step - loss: 0.3201 - accuracy: 0.8747\n",
      "Start training for (learn=0.001 - momentum=0.5 - candidates=0.3\n",
      "10415/10415 [==============================] - 14s 1ms/step - loss: 0.3380 - accuracy: 0.8689\n",
      "Start training for (learn=0.001 - momentum=0.5 - candidates=0.5\n",
      "10415/10415 [==============================] - 13s 1ms/step - loss: 0.3685 - accuracy: 0.8603\n",
      "Start training for (learn=0.001 - momentum=0.99 - candidates=0.1\n",
      "10415/10415 [==============================] - 15s 1ms/step - loss: 0.4319 - accuracy: 0.8374\n",
      "Start training for (learn=0.001 - momentum=0.99 - candidates=0.3\n",
      "10415/10415 [==============================] - 35s 3ms/step - loss: 0.5313 - accuracy: 0.8052\n",
      "Start training for (learn=0.001 - momentum=0.99 - candidates=0.5\n",
      "10415/10415 [==============================] - 41s 4ms/step - loss: 0.5973 - accuracy: 0.7636\n",
      "Start training for (learn=0.01 - momentum=0.0 - candidates=0.1\n",
      "10415/10415 [==============================] - 44s 4ms/step - loss: 0.3391 - accuracy: 0.8687\n",
      "Start training for (learn=0.01 - momentum=0.0 - candidates=0.3\n",
      "10415/10415 [==============================] - 15s 1ms/step - loss: 0.3702 - accuracy: 0.8617\n",
      "Start training for (learn=0.01 - momentum=0.0 - candidates=0.5\n",
      "10415/10415 [==============================] - 15s 1ms/step - loss: 0.4070 - accuracy: 0.8546\n",
      "Start training for (learn=0.01 - momentum=0.5 - candidates=0.1\n",
      "10415/10415 [==============================] - 28s 3ms/step - loss: 0.3484 - accuracy: 0.8647\n",
      "Start training for (learn=0.01 - momentum=0.5 - candidates=0.3\n",
      "10415/10415 [==============================] - 25s 2ms/step - loss: 0.3791 - accuracy: 0.8570\n",
      "Start training for (learn=0.01 - momentum=0.5 - candidates=0.5\n",
      "10415/10415 [==============================] - 26s 2ms/step - loss: 0.4304 - accuracy: 0.8362\n",
      "Start training for (learn=0.01 - momentum=0.99 - candidates=0.1\n",
      "10415/10415 [==============================] - 17s 2ms/step - loss: 1.0320 - accuracy: 0.4180\n",
      "Start training for (learn=0.01 - momentum=0.99 - candidates=0.3\n",
      "10415/10415 [==============================] - 27s 3ms/step - loss: 1.0817 - accuracy: 0.3839\n",
      "Start training for (learn=0.01 - momentum=0.99 - candidates=0.5\n",
      "10415/10415 [==============================] - 24s 2ms/step - loss: 1.0782 - accuracy: 0.3839\n"
     ]
    }
   ],
   "source": [
    "search_results = []\n",
    "\n",
    "learning_rate_candidates = [\n",
    "        0.001, 0.01\n",
    "]\n",
    "momentum_candidates = [\n",
    "        0.0, 0.5, 0.99\n",
    "]\n",
    "dropout_candidates = [\n",
    "        0.1, 0.3, 0.5\n",
    "]\n",
    "#optimizer = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "for nb_learn in learning_rate_candidates:\n",
    "    for nb_momentum in momentum_candidates:\n",
    "        for nb_dropout in dropout_candidates:\n",
    "            \n",
    "            optimizer = RMSprop(learning_rate=nb_learn, momentum=nb_momentum)\n",
    "            #optimizer.learning_rate.assign(nb_learn)\n",
    "            #optimizer.momentum.assign(nb_momentum)\n",
    "\n",
    "            print(f\"Start training for (learn={nb_learn} - momentum={nb_momentum} - candidates={nb_dropout}\")\n",
    "    \n",
    "          ########################################\n",
    "          # Use your own model here!!\n",
    "          ########################################\n",
    "            model = Sequential([\n",
    "            Dense(128, activation='relu', input_dim=25),\n",
    "                Dropout(nb_dropout),\n",
    "            Dense(64, activation='relu'),\n",
    "                Dropout(nb_dropout),\n",
    "            Dense(32, activation='relu'),\n",
    "                Dropout(nb_dropout),\n",
    "            Dense(3, activation='softmax')\n",
    "            ])\n",
    "            \n",
    "            model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "            \n",
    "            \n",
    "          #model = Sequential([\n",
    "          #  Conv2D(\n",
    "          #      nb_filters, kernel_size=2, padding='valid',\n",
    "          #      activation='relu', input_shape=x_train[0].shape\n",
    "          #  ),\n",
    "          #  Conv2D(\n",
    "          #      int(nb_filters*2), kernel_size=2,\n",
    "          #      padding='valid', activation='relu'\n",
    "          #  ),\n",
    "          #  MaxPooling2D(pool_size=2),\n",
    "          #  Dropout(dropout),\n",
    "          #  Flatten(),\n",
    "          #  Dense(nb_dense, activation='relu'),\n",
    "          #  Dropout(dropout),\n",
    "          #  Dense(10, activation='softmax')\n",
    "          #])\n",
    "          #model.compile(\n",
    "          #    loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']\n",
    "          #)\n",
    "          ########################################\n",
    "    \n",
    "          # we choose our best model as the one having the highest validation accuracy\n",
    "            filepath = f\"NN_train_results/cnn_paramsearch_filters_l={nb_learn}_mo={nb_momentum}_dr={nb_dropout}_dense=3.hdf5\"\n",
    "            checkpoint = ModelCheckpoint(\n",
    "                filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max'\n",
    "            )\n",
    "    \n",
    "          #batch_size=512, epochs=50, verbose=1, validation_data=(X_val, y_val)\n",
    "        \n",
    "            fit_results = model.fit(\n",
    "              x=X_train,\n",
    "              y=y_train,\n",
    "              batch_size=512,\n",
    "              # reduce number of epochs for speed reasons --> should be higher!\n",
    "              epochs=65,\n",
    "              validation_data=(X_val, y_val),\n",
    "              callbacks=[checkpoint],\n",
    "              verbose=0\n",
    "            )\n",
    "    \n",
    "            # extract the best validation scores\n",
    "            best_val_epoch    = np.argmax(fit_results.history['val_accuracy'])\n",
    "            best_val_acc      = np.max(fit_results.history['val_accuracy'])\n",
    "            best_val_acc_loss = fit_results.history['val_loss'][best_val_epoch]\n",
    "      \n",
    "            # get correct training accuracy\n",
    "            best_model = load_model(filepath)\n",
    "            best_val_acc_train_loss, best_val_acc_train_acc = best_model.evaluate(X_train, y_train)\n",
    "      \n",
    "            # store results\n",
    "            search_results.append({\n",
    "                'nb_learn': nb_learn,\n",
    "                'nb_momentum': nb_momentum,\n",
    "                'nb_dropout': nb_dropout,\n",
    "                #'dropout': dropout,\n",
    "                'best_val_acc_train_acc': best_val_acc_train_acc,\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'best_val_acc_train_loss': best_val_acc_train_loss,\n",
    "                'best_val_acc_loss': best_val_acc_loss,\n",
    "                'best_val_epoch': best_val_epoch\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dd71f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_learn</th>\n",
       "      <th>nb_momentum</th>\n",
       "      <th>nb_dropout</th>\n",
       "      <th>best_val_acc_train_acc</th>\n",
       "      <th>best_val_acc</th>\n",
       "      <th>best_val_acc_train_loss</th>\n",
       "      <th>best_val_acc_loss</th>\n",
       "      <th>best_val_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.874701</td>\n",
       "      <td>0.870848</td>\n",
       "      <td>0.320075</td>\n",
       "      <td>0.330313</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.873930</td>\n",
       "      <td>0.870428</td>\n",
       "      <td>0.321748</td>\n",
       "      <td>0.331930</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.868859</td>\n",
       "      <td>0.866479</td>\n",
       "      <td>0.337045</td>\n",
       "      <td>0.344021</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.868949</td>\n",
       "      <td>0.865975</td>\n",
       "      <td>0.337983</td>\n",
       "      <td>0.345809</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.868733</td>\n",
       "      <td>0.865387</td>\n",
       "      <td>0.339149</td>\n",
       "      <td>0.347830</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.864664</td>\n",
       "      <td>0.862410</td>\n",
       "      <td>0.348395</td>\n",
       "      <td>0.356400</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.863022</td>\n",
       "      <td>0.861258</td>\n",
       "      <td>0.361447</td>\n",
       "      <td>0.366212</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.859878</td>\n",
       "      <td>0.370242</td>\n",
       "      <td>0.375239</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.860313</td>\n",
       "      <td>0.858762</td>\n",
       "      <td>0.368537</td>\n",
       "      <td>0.372822</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.856985</td>\n",
       "      <td>0.854080</td>\n",
       "      <td>0.379130</td>\n",
       "      <td>0.385344</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.854617</td>\n",
       "      <td>0.853288</td>\n",
       "      <td>0.406955</td>\n",
       "      <td>0.410545</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.837351</td>\n",
       "      <td>0.836172</td>\n",
       "      <td>0.431875</td>\n",
       "      <td>0.435704</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.836151</td>\n",
       "      <td>0.834348</td>\n",
       "      <td>0.430388</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.805156</td>\n",
       "      <td>0.803236</td>\n",
       "      <td>0.531316</td>\n",
       "      <td>0.534185</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.763632</td>\n",
       "      <td>0.763578</td>\n",
       "      <td>0.597309</td>\n",
       "      <td>0.599355</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.418012</td>\n",
       "      <td>0.416802</td>\n",
       "      <td>1.032044</td>\n",
       "      <td>1.034793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.383945</td>\n",
       "      <td>0.384154</td>\n",
       "      <td>1.081667</td>\n",
       "      <td>1.082368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.383945</td>\n",
       "      <td>0.384154</td>\n",
       "      <td>1.078214</td>\n",
       "      <td>1.078863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_learn  nb_momentum  nb_dropout  best_val_acc_train_acc  best_val_acc  \\\n",
       "3      0.001         0.50         0.1                0.874701      0.870848   \n",
       "0      0.001         0.00         0.1                0.873930      0.870428   \n",
       "1      0.001         0.00         0.3                0.868859      0.866479   \n",
       "4      0.001         0.50         0.3                0.868949      0.865975   \n",
       "9      0.010         0.00         0.1                0.868733      0.865387   \n",
       "12     0.010         0.50         0.1                0.864664      0.862410   \n",
       "2      0.001         0.00         0.5                0.863022      0.861258   \n",
       "10     0.010         0.00         0.3                0.861702      0.859878   \n",
       "5      0.001         0.50         0.5                0.860313      0.858762   \n",
       "13     0.010         0.50         0.3                0.856985      0.854080   \n",
       "11     0.010         0.00         0.5                0.854617      0.853288   \n",
       "6      0.001         0.99         0.1                0.837351      0.836172   \n",
       "14     0.010         0.50         0.5                0.836151      0.834348   \n",
       "7      0.001         0.99         0.3                0.805156      0.803236   \n",
       "8      0.001         0.99         0.5                0.763632      0.763578   \n",
       "15     0.010         0.99         0.1                0.418012      0.416802   \n",
       "16     0.010         0.99         0.3                0.383945      0.384154   \n",
       "17     0.010         0.99         0.5                0.383945      0.384154   \n",
       "\n",
       "    best_val_acc_train_loss  best_val_acc_loss  best_val_epoch  \n",
       "3                  0.320075           0.330313              62  \n",
       "0                  0.321748           0.331930              53  \n",
       "1                  0.337045           0.344021              63  \n",
       "4                  0.337983           0.345809              64  \n",
       "9                  0.339149           0.347830              48  \n",
       "12                 0.348395           0.356400              46  \n",
       "2                  0.361447           0.366212              55  \n",
       "10                 0.370242           0.375239              45  \n",
       "5                  0.368537           0.372822              40  \n",
       "13                 0.379130           0.385344              64  \n",
       "11                 0.406955           0.410545              62  \n",
       "6                  0.431875           0.435704              41  \n",
       "14                 0.430388           0.433000              47  \n",
       "7                  0.531316           0.534185              64  \n",
       "8                  0.597309           0.599355               2  \n",
       "15                 1.032044           1.034793               0  \n",
       "16                 1.081667           1.082368               1  \n",
       "17                 1.078214           1.078863               0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(search_results)\n",
    "\n",
    "# sort values\n",
    "resultsDF.sort_values('best_val_acc', ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f428548f",
   "metadata": {},
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad7708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "33d83e1d",
   "metadata": {},
   "source": [
    "tensor_features = tf.convert_to_tensor(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15be12fc",
   "metadata": {},
   "source": [
    "tensor_features"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ea40fbd",
   "metadata": {},
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(tensor_features)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a72ee554",
   "metadata": {},
   "source": [
    "tensor_features"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e069eb9d",
   "metadata": {},
   "source": [
    "normalizer(tensor_features.iloc[:3])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa9a7ae0",
   "metadata": {},
   "source": [
    "for i in (normed_features):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c9973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab8cba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d0ec51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
